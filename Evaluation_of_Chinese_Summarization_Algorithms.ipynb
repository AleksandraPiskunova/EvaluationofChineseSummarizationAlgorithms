{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluation of Chinese Summarization Algorithms.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHHu7oRprLxz"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44ckt2nmkS0V"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"zh_core_web_sm\") # to split texts into sentences\n",
        "import re\n",
        "import os\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBGlXUaPyRfh"
      },
      "source": [
        "from fastHan import FastHan # to split sentences into words\n",
        "model = FastHan(model_type = \"large\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14v44-I-yjdY"
      },
      "source": [
        "model.set_cws_style('ctb')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH8GnQmdrYM6"
      },
      "source": [
        "PATH = \"\"\n",
        "SUMMPATH = \"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRCnYsucrgys"
      },
      "source": [
        "# to get the texts\n",
        "texts_pathes = os.listdir(PATH)\n",
        "texts_pathes = sorted(texts_pathes)\n",
        "# print(texts_pathes)\n",
        "texts = []\n",
        "for text in texts_pathes:\n",
        "  text = open(os.path.join(PATH, text),\"r\", encoding = \"utf-8\")\n",
        "  text = text.read()\n",
        "  texts.append(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vag9ItB8Vrcw"
      },
      "source": [
        "# to get the summaries\n",
        "summ_paths = os.listdir(SUMMPATH)\n",
        "summ_paths = sorted(summ_paths)\n",
        "# print(summ_paths)\n",
        "summaries = []\n",
        "for summary in summ_paths:\n",
        "  summary = open(os.path.join(SUMMPATH, summary),\"r\", encoding = \"utf-8\")\n",
        "  summary = summary.read()\n",
        "  summaries.append(summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypO6gKmidH__"
      },
      "source": [
        "!pip install rouge-metric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke1_xosYdiQJ"
      },
      "source": [
        "from rouge_metric import PyRouge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPaEv56ydscD"
      },
      "source": [
        "rouge = PyRouge(rouge_n=(1, 2, 4), rouge_l=True, rouge_w=True,\n",
        "                rouge_w_weight=1.2, rouge_s=True, rouge_su=True, skip_gap=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nxkkg_RvMGTE"
      },
      "source": [
        "# to help ROUGE\n",
        "def preprocess_tokenize(text):\n",
        "  sentences = list(map(lambda sent: sent + '。', text.split('。')))[:-1]\n",
        "  tokenized_sentences = list(map(lambda sent: \" \".join(model(sent, target = \"CWS\")[0]), sentences))\n",
        "  tokenized_sentence = \" \".join(tokenized_sentences)\n",
        "  return tokenized_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY-36J3lbphc"
      },
      "source": [
        "def evaluate_rouge(summary, prediction):\n",
        "  # tokenized_summary = model(summary, target = \"CWS\")\n",
        "  # tokenized_summary = \" \".join(tokenized_summary[0])\n",
        "  tokenized_summary = preprocess_tokenize(summary)\n",
        "  score = rouge.evaluate([tokenized_summary], [[prediction]])\n",
        "  return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDMt_kbfPzCX"
      },
      "source": [
        "# to evaluate summaries\n",
        "def evaluate_predictions(summaries, predictions):\n",
        "  rouge_scores = []\n",
        "  for summary, prediction in zip(summaries, predictions):\n",
        "    score = evaluate_rouge(summary, prediction)\n",
        "    rouge_scores.append(score)\n",
        "  return rouge_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e7Xm5vG0EKQ"
      },
      "source": [
        "# to find Recall, Precision and F-score\n",
        "def avg_score(score_dicts_list):\n",
        "  avg_score = {}\n",
        "  for key in score_dicts_list[0].keys():\n",
        "    avg_score[key] = {}\n",
        "    avg_score[key]['f'] = sum([rouge_score[key]['f'] for rouge_score in score_dicts_list]) / len(score_dicts_list)\n",
        "    avg_score[key]['p'] = sum([rouge_score[key]['p'] for rouge_score in score_dicts_list]) / len(score_dicts_list)\n",
        "    avg_score[key]['r'] = sum([rouge_score[key]['r'] for rouge_score in score_dicts_list]) / len(score_dicts_list)\n",
        "  return avg_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVMSlK95xYaq"
      },
      "source": [
        "# to evaluate TextRank4Zh\n",
        "!pip3 install textrank4zh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6WYs6jwxoC4"
      },
      "source": [
        "from textrank4zh import TextRank4Sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-5CJYlGxraT"
      },
      "source": [
        "# to make a summary of TextRank4Zh more similar to standard summary\n",
        "def post_processed__TextRank4zh_text(text, n):\n",
        "  tr4s = TextRank4Sentence()\n",
        "  tr4s.analyze(text)\n",
        "  summary = tr4s.get_key_sentences(num=n)\n",
        "\n",
        "  tokenized_sentences = []\n",
        "  sentences = [item.sentence for item in summary]\n",
        "  for sentence in sentences:\n",
        "    sentence = sentence.strip(\"\\n\")\n",
        "    sentence = model(sentence, target = \"CWS\")\n",
        "    sentence = \" \".join(sentence[0])\n",
        "    #print(sentence)\n",
        "    tokenized_sentences.append(sentence)\n",
        "  #print(len(tokenized_sentences))\n",
        "  whole_text = \"。\".join(tokenized_sentences)  \n",
        "  whole_text += \"。\"\n",
        "  return whole_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_X4M2x5xz9Y"
      },
      "source": [
        "# to get a summary from TextRank4Zh\n",
        "TextRank4Zh_summaries = []\n",
        "for text in texts:\n",
        "  new_text = post_processed__TextRank4zh_text(text, 8)\n",
        "  TextRank4Zh_summaries.append(new_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8nZiTHHQlDm"
      },
      "source": [
        "textrank4zh_rouge_scores = evaluate_predictions(summaries, TextRank4Zh_summaries)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX0PjuHn4m4D"
      },
      "source": [
        "textrank4zh_avg_scores = avg_score(textrank4zh_rouge_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prNVL9-a4qnt"
      },
      "source": [
        "with open('/content/rouge_results/textrank4zh_avg_scores.json', 'w') as res_json:\n",
        "  json.dump(textrank4zh_avg_scores, res_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-36GwBGqztU4"
      },
      "source": [
        "# to evaluate Macropodus\n",
        "!pip install macropodus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvoOvXqIzv7H"
      },
      "source": [
        "import macropodus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqIpyFebzyqk"
      },
      "source": [
        "# to make a summary of Macropodus more similar to standard summary\n",
        "def post_processed__Macropodus_text(text, n, sum_type, model_type, type_l):\n",
        "  sentences = macropodus.summarization(text = text, type_summarize = sum_type, num = n, model_type = model_type, type_l = type_l)\n",
        "\n",
        "  tokenized_sentences = []\n",
        "  for sentence in sentences:\n",
        "    sentence = sentence[1].strip(\"\\n\")\n",
        "    sentence = model(sentence, target = \"CWS\")\n",
        "    sentence = \" \".join(sentence[0])\n",
        "    #print(sentence)\n",
        "    tokenized_sentences.append(sentence)\n",
        "\n",
        "  whole_text = \"。\".join(tokenized_sentences)  \n",
        "  whole_text += \"。\"\n",
        "  return whole_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75Ac7om4z02Y"
      },
      "source": [
        "# to get a summary from Macropodus//lda\n",
        "Macropodus_LDA_summaries = []\n",
        "for new_text in texts:\n",
        "  new_text = post_processed__Macropodus_text(text, 8, \"lda\", model_type = None, type_l = None)\n",
        "  Macropodus_LDA_summaries.append(new_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDVmAsdoRX4Y"
      },
      "source": [
        "macropodus_lda_rouge_scores = evaluate_predictions(summaries, Macropodus_LDA_summaries)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPQKKswh50Po"
      },
      "source": [
        "macropodus_lda_avg_scores = avg_score(macropodus_lda_rouge_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2_4V9ge50Pp"
      },
      "source": [
        "with open('/content/rouge_results/macropodus_lda_avg_scores.json', 'w') as res_json:\n",
        "  json.dump(macropodus_lda_avg_scores, res_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVhOi_yd1yNM"
      },
      "source": [
        "# to get a summary from Macropodus//pronouns\n",
        "Macropodus_pronouns_summaries = []\n",
        "for text in texts:\n",
        "  text = post_processed__Macropodus_text(text, 8, \"text_pronouns\", model_type = None, type_l = None)\n",
        "  Macropodus_pronouns_summaries.append(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8eUGenkd_03"
      },
      "source": [
        "macropodus_pronouns_rouge_scores = evaluate_predictions(summaries, Macropodus_pronouns_summaries)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCVKlMHA7Asr"
      },
      "source": [
        "macropodus_pronouns_avg_scores = avg_score(macropodus_pronouns_rouge_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxD-F_rf7Ast"
      },
      "source": [
        "with open('/content/rouge_results/macropodus_pronouns_avg_scores.json', 'w') as res_json:\n",
        "  json.dump(macropodus_pronouns_avg_scores, res_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKFf45qB1yf6"
      },
      "source": [
        "# to get a summary from Macropodus//text_teaser\n",
        "Macropodus_text_teaser_summaries = []\n",
        "for text in texts:\n",
        "  text = post_processed__Macropodus_text(text, 8, \"text_teaser\", model_type = \"sklearn\", type_l = None)\n",
        "  Macropodus_text_teaser_summaries.append(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R327nbcceI5-"
      },
      "source": [
        "macropodus_text_teaser_rouge_scores = evaluate_predictions(summaries, Macropodus_text_teaser_summaries)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4SSmpM97RpJ"
      },
      "source": [
        "macropodus_text_teaser_avg_scores = avg_score(macropodus_text_teaser_rouge_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXLNridU7RpK"
      },
      "source": [
        "with open('/content/rouge_results/macropodus_text_teaser_avg_scores.json', 'w') as res_json:\n",
        "  json.dump(macropodus_text_teaser_avg_scores, res_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM_84o-A1yw2"
      },
      "source": [
        "# to get a summary from Macropodus//word_sign\n",
        "Macropodus_word_sign_summaries = []\n",
        "for text in texts:\n",
        "  text = post_processed__Macropodus_text(text, 8, \"word_sign\", model_type = None, type_l = None)\n",
        "  Macropodus_word_sign_summaries.append(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltCvabSDeQYY"
      },
      "source": [
        "macropodus_word_sign_rouge_scores = evaluate_predictions(summaries, Macropodus_word_sign_summaries)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsPMSRy17gYF"
      },
      "source": [
        "macropodus_word_sign_avg_scores = avg_score(macropodus_word_sign_rouge_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKLPwadW7gYH"
      },
      "source": [
        "with open('/content/rouge_results/macropodus_word_sign_avg_scores.json', 'w') as res_json:\n",
        "  json.dump(macropodus_word_sign_avg_scores, res_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHSCZKLA6Klp"
      },
      "source": [
        "# to get a summary from Macropodus//mmr\n",
        "Macropodus_mmr_summaries = []\n",
        "for text in texts:\n",
        "  text = post_processed__Macropodus_text(text, 8, \"mmr\", model_type = None, type_l = None)\n",
        "  Macropodus_mmr_summaries.append(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsLf_fuyeZAB"
      },
      "source": [
        "macropodus_mmr_rouge_scores = evaluate_predictions(summaries, Macropodus_mmr_summaries)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KM7A2sr7xIR"
      },
      "source": [
        "macropodus_mmr_avg_scores = avg_score(macropodus_mmr_rouge_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1XYEMZM7xIT"
      },
      "source": [
        "with open('/content/rouge_results/macropodus_mmr_avg_scores.json', 'w') as res_json:\n",
        "  json.dump(macropodus_mmr_avg_scores, res_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnxt_gn36Vvl"
      },
      "source": [
        "# to get a summary from Macropodus//lsi\n",
        "Macropodus_lsi_summaries = []\n",
        "for text in texts:\n",
        "  text = post_processed__Macropodus_text(text, 8, \"lsi\", model_type = None, type_l = None)\n",
        "  Macropodus_lsi_summaries.append(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yljkNLyHejM4"
      },
      "source": [
        "macropodus_lsi_rouge_scores = evaluate_predictions(summaries, Macropodus_lsi_summaries)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eufsw6wV78oo"
      },
      "source": [
        "macropodus_lsi_avg_scores = avg_score(macropodus_lsi_rouge_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dW-AsZY78op"
      },
      "source": [
        "with open('/content/rouge_results/macropodus_lsi_avg_scores.json', 'w') as res_json:\n",
        "  json.dump(macropodus_lsi_avg_scores, res_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmb-RodS6dla"
      },
      "source": [
        "# to get a summary from Macropodus//nmf\n",
        "Macropodus_nmf_summaries = []\n",
        "for text in texts:\n",
        "  text = post_processed__Macropodus_text(text, 8, \"nmf\", model_type = None, type_l = None)\n",
        "  Macropodus_nmf_summaries.append(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgCjyHuweopb"
      },
      "source": [
        "macropodus_nmf_rouge_scores = evaluate_predictions(summaries, Macropodus_nmf_summaries)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5RWJFNN8JYL"
      },
      "source": [
        "macropodus_nmf_avg_scores = avg_score(macropodus_nmf_rouge_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kisa6giE8JYN"
      },
      "source": [
        "with open('/content/rouge_results/macropodus_nmf_avg_scores.json', 'w') as res_json:\n",
        "  json.dump(macropodus_nmf_avg_scores, res_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77VtHNjs62yc"
      },
      "source": [
        "# to evaluate SnowNLP\n",
        "!pip install snownlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0mORLt07GsX"
      },
      "source": [
        "from snownlp import SnowNLP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VvgWbsT6vv9"
      },
      "source": [
        "# to make a summary of SnowNLP more similar to standard summary\n",
        "def post_processed_SnowNLP_text(text, n):\n",
        "  sentences = SnowNLP(text)\n",
        "  sentences = sentences.summary(n)\n",
        "\n",
        "  tokenized_sentences = []\n",
        "  for sentence in sentences:\n",
        "    sentence = sentence.strip(\"\\n\")\n",
        "    sentence = model(sentence, target = \"CWS\")\n",
        "    sentence = \" \".join(sentence[0])\n",
        "    #print(sentence)\n",
        "    tokenized_sentences.append(sentence)\n",
        "\n",
        "  whole_text = \"。\".join(tokenized_sentences)  \n",
        "  whole_text += \"。\"\n",
        "  return whole_text  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfZhfigs7OlG"
      },
      "source": [
        "# to get a summary from SnowNLP\n",
        "SnowNLP_summaries = []\n",
        "for text in texts:\n",
        "  new_text = post_processed_SnowNLP_text(text, 8)\n",
        "  SnowNLP_summaries.append(new_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOcL0wqpewYS"
      },
      "source": [
        "snownlp_rouge_scores = evaluate_predictions(summaries, SnowNLP_summaries)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPLJs6oo8X0k"
      },
      "source": [
        "snownlp_avg_scores = avg_score(snownlp_rouge_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UrbNrWV8X0l"
      },
      "source": [
        "with open('/content/rouge_results/snownlp_avg_scores.json', 'w') as res_json:\n",
        "  json.dump(snownlp_avg_scores, res_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS5l0giB7qmO"
      },
      "source": [
        "# to evaluate Lead-3\n",
        "Lead3_baselines = []\n",
        "for text in texts:\n",
        "  new_text = post_processed__Macropodus_text(text, 8, \"lead3\", model_type = None, type_l =\"mix\")\n",
        "  Lead3_baselines.append(new_text)\n",
        "print(Lead3_baselines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WgBFXMNdiMJ"
      },
      "source": [
        "lead3_rouge_scores = evaluate_predictions(summaries, Lead3_baselines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F17C9qTs8iOo"
      },
      "source": [
        "lead3_avg_scores = avg_score(lead3_rouge_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tCUNhcQ8iOq"
      },
      "source": [
        "with open('/content/rouge_results/lead3_avg_scores.json', 'w') as res_json:\n",
        "  json.dump(lead3_avg_scores, res_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lu8RYfzxiMnE"
      },
      "source": [
        "# OpenNMT-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2epTd9lSiPkx"
      },
      "source": [
        "# to evaluate OpenNMT-py\n",
        "!pip install git+https://github.com/OpenNMT/OpenNMT-py@585499a450"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MoYKj-Ojnz4"
      },
      "source": [
        "def preprocess_opennmt(text):\n",
        "  processed_text = re.sub(\"\\n\", \" \", text)\n",
        "  processed_text = ' '.join(list(processed_text))\n",
        "  return processed_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxctorwcj_SN"
      },
      "source": [
        "processed_for_onmt = []\n",
        "for text in texts:\n",
        "  processed_text = preprocess_opennmt(text)\n",
        "  processed_for_onmt.append(processed_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcX1mvakkSG_"
      },
      "source": [
        "for index, text in enumerate(processed_for_onmt):\n",
        "  with open(os.path.join(ONMT_PATH, str(index)) + '.txt', \"w\") as f:\n",
        "    f.write(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8klCWTJolOdY"
      },
      "source": [
        "# to apply onmt model for all preprocessed texts\n",
        "for index, text in enumerate(os.listdir(ONMT_PATH)):\n",
        "  !onmt_translate -model /content/drive/MyDrive/магистратура/db_chinese_text_summarization/chinese_opennmt_lcsts_acc_56.86_ppl_10.97_e11.pt -src /content/onmt_data/{text} -output /content/onmt_data/summaries/{index}_summary.txt -verbose"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY0j7M9QoBBH"
      },
      "source": [
        "onmt_preds = []\n",
        "for summary in os.listdir(ONMT_SUMMARIES_PATH):\n",
        "  with open(os.path.join(ONMT_SUMMARIES_PATH, summary), \"r\") as pred:\n",
        "    opennmt_results = pred.read()\n",
        "    onmt_preds.append(opennmt_results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLHwgFB5omqk"
      },
      "source": [
        "# to make a summary of Open-NMT more similar to standard summary\n",
        "def post_process_onmt(text):\n",
        "  text = text.strip(\"\\n\")\n",
        "  text = model(text, target = \"CWS\")\n",
        "  text = \" \".join(text[0])\n",
        "  #print(sentence) \n",
        "  text += \"。\"\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heHnQ0zvqvQb"
      },
      "source": [
        "# to get a summary from Open-NMT\n",
        "onmt_summaries =[]\n",
        "for pred in onmt_preds:\n",
        "  processed = post_process_onmt(pred)\n",
        "  onmt_summaries.append(processed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLefeTWnrljQ"
      },
      "source": [
        "onmt_rouge_scores = evaluate_predictions(summaries, onmt_summaries)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3a8zd5H8s_U"
      },
      "source": [
        "onmt_avg_scores = avg_score(onmt_rouge_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvDx4tTB8s_W"
      },
      "source": [
        "with open('/content/rouge_results/onmt_avg_scores.json', 'w') as res_json:\n",
        "  json.dump(onmt_avg_scores, res_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQHOPNsh9i55"
      },
      "source": [
        "# to evaluate Bert Extractive Summarizer\n",
        "!pip install bert-extractive-summarizer\n",
        "!pip install spacy==2.3.1\n",
        "!pip install transformers\n",
        "!pip install neuralcoref"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFmPwsew9oWV"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsGkADmK93Mh"
      },
      "source": [
        "!python -m spacy download zh_core_web_lg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCSXOpoP96pY"
      },
      "source": [
        "import spacy\n",
        "import zh_core_web_lg\n",
        "import neuralcoref"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUUWJ9Kp-JAw"
      },
      "source": [
        "nlp = zh_core_web_lg.load()\n",
        "neuralcoref.add_to_pipe(nlp)\n",
        "\n",
        "from summarizer import Summarizer\n",
        "from summarizer.sentence_handler import SentenceHandler\n",
        "from spacy.lang.zh import Chinese\n",
        "from transformers import *\n",
        "\n",
        "# Load model, model config and tokenizer via Transformers\n",
        "modelName = \"bert-base-chinese\" \n",
        "custom_config = AutoConfig.from_pretrained(modelName)\n",
        "custom_config.output_hidden_states=True\n",
        "custom_tokenizer = AutoTokenizer.from_pretrained(modelName)\n",
        "custom_model = AutoModel.from_pretrained(modelName, config=custom_config)\n",
        "\n",
        "bert_model = Summarizer(\n",
        "    custom_model=custom_model, \n",
        "    custom_tokenizer=custom_tokenizer,\n",
        "    sentence_handler = SentenceHandler(language=Chinese)\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHq-IWw9FxC2"
      },
      "source": [
        "# to make a summary of BertExtractiveSummarizer more similar to standard summary\n",
        "def post_process_bert_extractive(text):\n",
        "  text = re.sub(\"\\n\", \" \", text)\n",
        "  sentences = text.split(\"。\")\n",
        "  tokenized_sentences = []\n",
        "  for sent in sentences:\n",
        "    sent = model(sent, target = \"CWS\")\n",
        "    sent = \" \".join(sent[0])\n",
        "    tokenized_sentences.append(sent)\n",
        "\n",
        "  whole_text = \"。\".join(tokenized_sentences)  \n",
        "  whole_text += \"。\"\n",
        "  return whole_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlCSQDrWB478"
      },
      "source": [
        "# to get a summary from BertExtractiveSummarizer\n",
        "bert_extractive_summaries = []\n",
        "for index, text in enumerate(texts):\n",
        "  print(index)\n",
        "  raw_summary = bert_model(text, num_sentences = 8)\n",
        "  summary = post_process_bert_extractive(raw_summary)\n",
        "  bert_extractive_summaries.append(summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTEMEa78DElQ"
      },
      "source": [
        "bert_extractive_rouge_scores = evaluate_predictions(summaries, bert_extractive_summaries)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmTv7gSxGcE5"
      },
      "source": [
        "bert_extractive_avg_scores = avg_score(bert_extractive_rouge_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USkMC2ZkGcE7"
      },
      "source": [
        "with open('/content/rouge_results/bert_extractive_avg_scores.json', 'w') as res_json:\n",
        "  json.dump(bert_extractive_avg_scores, res_json)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}